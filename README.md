# Лабораторная работа 6. Семантическая сегментация

Для данной работы необходимо скачать архив с датасетом по ссылке: https://disk.yandex.ru/d/-Rvv2UQlHVL04w

Выполнение работы дает 15 баллов независимо от итогового mIoU на тестовой выборке, но mIoU более 0.6 дает дополнительно еще 5 баллов

Возможные вопросы от преподавателя на защите:
1. Что такое семантическая сегментация?
2. Каковы особенности архитектуры нейронных сетей для семантической сегментации?
3. Как работает свертка?
4. Можно ли использовать трансформерные архитектуры для семантической сегментации и в чем будут состоять ограничения для их использования?
5. Какая метрика используется для оценки качества таких моделей и как она вычисляется?


## 1. Что такое семантическая сегментация?
Семантическая сегментация — это задача в области компьютерного зрения, заключающаяся в классификации каждого пикселя изображения в один из заранее определённых классов. В отличие от задачи классификации, где изображение получает одну метку, семантическая сегментация даёт метку каждому пикселю, например, «небо», «дорога», «дерево», «человек» и так далее.

Основной целью является разбиение изображения на области, соответствующие различным объектам или фонам, с учётом их семантической значимости. Это важно для приложений, где требуется точное понимание структуры сцены, например, в автономных автомобилях, медицинской визуализации, робототехнике.

Пример: на изображении с дорогой и пешеходами каждый пиксель будет помечен как «дорога», «пешеход» или «небо», в зависимости от того, к какому объекту он относится.

## 2. Каковы особенности архитектуры нейронных сетей для семантической сегментации?

Архитектуры нейронных сетей для семантической сегментации имеют несколько ключевых особенностей, которые отличают их от архитектур для других задач компьютерного зрения. Вот основные из них:

### 1. **Encoder-Decoder архитектуры**
   Семантическая сегментация часто используется с архитектурами, которые состоят из двух частей:
   - **Encoder (сжатие)** — часть сети, которая извлекает особенности из изображения и сжимает его информацию, например, с помощью сверточных слоёв. Обычно используется для выделения абстрактных признаков, таких как контуры объектов, текстуры, формы.
   - **Decoder (декодирование)** — восстанавливает пространственную информацию, преобразуя представления, полученные на этапе сжатия, обратно в карту с высокой разрешающей способностью (размер карты соответствует размеру исходного изображения).

   Пример: **U-Net** — популярная архитектура для сегментации, которая включает в себя симметричную структуру энкодера и декодера с пропускными связями (skip connections).

### 2. **Скачивание пространственного разрешения (Pooling) и восстановление (Upsampling)**
   Во время сжатия изображение теряет пространственное разрешение, что приводит к уменьшению детализации. Для восстановления разрешения в декодере часто применяются:
   - **Upsampling** или **Deconvolution (Transposed Convolution)** для увеличения разрешения карты признаков.
   - Пропускные связи между слоями энкодера и декодера, которые помогают передавать пространственную информацию и восстанавливать утраченные детали.

### 3. **Пропускные связи (Skip Connections)**
   В таких архитектурах, как **U-Net**, пропускные связи играют важную роль. Они позволяют сохранять детали, потерянные в процессе сжатия, путём объединения (конкатенации) высокоуровневых признаков энкодера с низкоуровневыми признаками декодера. Это помогает сохранять контекст и точность сегментации, особенно для мелких объектов.

### 4. **Сегментация на уровне пикселей**
   Для каждого пикселя изображения сеть должна предсказать его метку. Это требует того, чтобы нейронная сеть использовала методы, которые могут работать с пространственными данными и сохранять локальную информацию на уровне каждого пикселя.

### 5. **Использование предобученных моделей**
   Многие архитектуры для сегментации используют предобученные модели на задачах классификации, таких как **ResNet** или **VGG**. Эти модели, обученные на огромных датасетах (например, ImageNet), извлекают высокоуровневые признаки, которые затем используются для задач сегментации. Это позволяет ускорить обучение и повысить качество модели.

### 6. **Функции потерь**
   Для задач сегментации часто используются специализированные функции потерь, такие как:
   - **Cross-entropy loss** для многоклассовой сегментации.
   - **Dice coefficient** и **IoU (Intersection over Union)** — метрики, которые более точно отражают качество сегментации, учитывая частичные пересечения объектов.

### 7. **Представление меток классов**
   Каждый пиксель на изображении классифицируется как принадлежащий одному из классов. В задачах многоклассовой сегментации, как правило, используется **softmax** на выходе сети для предсказания вероятности принадлежности пикселя к каждому из классов.

### 8. **Обработка объектов разного размера**
   Семантическая сегментация требует обработки объектов с разными размерами, что делает важным использование различных масштабов на разных уровнях сети. Это может быть реализовано через:
   - **Dilated convolutions** — расширенные свертки, которые позволяют захватывать контекст на большем масштабе без потери разрешения.
   - Многомасштабные подходы для учета как мелких, так и крупных объектов.

### 9. **Аугментации данных**
   Для улучшения качества сегментации часто используются аугментации данных, такие как:
   - Изменение масштаба и вращение изображения.
   - Добавление шума или изменения освещенности для улучшения обобщающей способности модели.

### Пример популярных архитектур:
- **U-Net** — одна из самых популярных архитектур для медицинской сегментации, с явными пропускными связями между энкодером и декодером.
- **FCN (Fully Convolutional Networks)** — сеть, которая заменяет все полносвязные слои на свёрточные, обеспечивая выходные карты той же размерности, что и входное изображение.
- **DeepLab** — использует **atrous convolution** (диализованные свертки) для сохранения разрешения и обработки объектов на разных масштабах.

Эти особенности делают нейронные сети для семантической сегментации мощными инструментами для задач, где необходимо точно понимать структуру и детали изображений на уровне каждого пикселя.

## 3. Как работает свертка?

Свертка (или **convolution**) — это математическая операция, широко используемая в нейронных сетях, особенно в сверточных нейронных сетях (CNN), для обработки изображений, сигналов и других данных. Суть свертки заключается в применении фильтра (ядра свертки) к входным данным с целью извлечения особенностей, таких как края, текстуры и формы.

### 1. **Основная идея**
Суть свертки заключается в том, что фильтр (или ядро свертки) перемещается по изображению (или другому виду входных данных) и вычисляет скалярное произведение (или сумму произведений) между весами фильтра и соответствующими значениями входного изображения.

### 2. **Как работает свертка: пошаговое описание**

Предположим, что у нас есть **входное изображение** размером \( M \times N \) и **фильтр (ядро)** размером \( k \times k \), где \( k \) — размер фильтра (например, 3x3, 5x5 и т. д.).

1. **Инициализация**: Фильтр имеет свои веса, которые могут быть случайно инициализированы в начале обучения. Например, для фильтра размером 3x3 весов будет 9.

2. **Применение фильтра**: Мы начинаем перемещать фильтр по изображению. На каждом шаге фильтр «накладывается» на определённую область изображения (обычно эту область называют **паддингом** или **областью свертывания**), и для каждого положения фильтра считается скалярное произведение между значениями пикселей этой области и значениями весов фильтра.

3. **Скалярное произведение**: Скалярное произведение между фильтром и локальной областью изображения вычисляется как сумма произведений соответствующих элементов:
   \[
   \text{output}(i,j) = \sum_{m=1}^{k} \sum_{n=1}^{k} \text{filter}(m,n) \cdot \text{image}(i+m-1, j+n-1)
   \]
   где \( i, j \) — индексы пикселей выходного изображения, а \( m, n \) — индексы внутри фильтра.

4. **Перемещение фильтра**: Фильтр двигается по изображению, обычно с шагом (stride) 1 (или больше) и повторяет процесс вычисления для каждого положения.

5. **Результат**: Результатом свертки является выходная карта (или **feature map**) меньших размеров (зависит от шага, паддинга и размеров фильтра). Каждый элемент в выходной карте соответствует свёрнутому значению для соответствующей области входного изображения.

### 3. **Пример**
Предположим, что у нас есть простое изображение 5x5 и фильтр 3x3. Изображение:

\[
\begin{pmatrix}
1 & 2 & 3 & 0 & 1 \\
4 & 5 & 6 & 1 & 0 \\
7 & 8 & 9 & 0 & 1 \\
1 & 2 & 3 & 4 & 5 \\
6 & 7 & 8 & 9 & 0 \\
\end{pmatrix}
\]

И фильтр 3x3:

\[
\begin{pmatrix}
0 & 1 & 0 \\
1 & -4 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
\]

Процесс свертки начинается с того, что фильтр накладывается на верхнюю левую часть изображения (например, на 3x3 область из первых трёх строк и первых трёх столбцов), и для этой области вычисляется скалярное произведение с фильтром:

\[
\text{output}(1,1) = (0 \times 1) + (1 \times 2) + (0 \times 3) + (1 \times 4) + (-4 \times 5) + (1 \times 6) + (0 \times 7) + (1 \times 8) + (0 \times 9) = 2 + 4 - 20 + 6 + 8 = 0
\]

Затем фильтр сдвигается на следующий участок изображения, и аналогичная операция повторяется для каждой области.

### 4. **Типы сверток**
- **Обычная свертка (Standard Convolution)**: описанная выше операция, когда фильтр накладывается на изображение и вычисляется скалярное произведение.
- **Затухающая свертка (Dilated Convolution)**: когда между элементами фильтра добавляются пропуски, что позволяет фильтру захватывать более широкий контекст, не увеличивая его размер.
- **Группированная свертка (Grouped Convolution)**: фильтр разделяется на несколько групп, и свертка выполняется отдельно для каждой группы. Это используется в некоторых эффективных моделях, таких как **MobileNet**.

### 5. **Роль свертки в нейронных сетях**
Свертки помогают нейронным сетям извлекать **локальные признаки** изображения. В отличие от полносвязных слоёв, которые используют все входные данные, сверточные слои работают с маленькими участками изображения, что позволяет сети:
- Сохранять пространственную информацию.
- Экономить вычислительные ресурсы за счёт меньшего количества параметров.
- Выучивать такие признаки, как контуры, текстуры и формы объектов.

С помощью нескольких свёрточных слоёв нейронная сеть может обучаться на разных уровнях представлений: от простых признаков (например, краёв) до более сложных, таких как текстуры и объекты.

### 6. **Паддинг и шаг (stride)**
- **Паддинг (Padding)**: добавление пустых пикселей (чаще всего нулевых) по краям изображения, чтобы сохранить размерность или контролировать размеры выходной карты.
- **Шаг (Stride)**: количество пикселей, на которое фильтр сдвигается при каждом шаге. Чем больше шаг, тем меньше размер выходного изображения.

Таким образом, свертка — это основная операция в сверточных нейронных сетях, которая позволяет моделям эффективно извлекать и обрабатывать признаки на изображениях, делая их важным инструментом для задач компьютерного зрения.

## 4. Можно ли использовать трансформерные архитектуры для семантической сегментации и в чем будут состоять ограничения для их использования?

Да, **трансформерные архитектуры** могут быть использованы для **семантической сегментации**, и их эффективность в этом контексте продолжает расти, особенно с развитием таких моделей, как **Vision Transformer (ViT)** и их производных, включая **SegFormer** и **Swin Transformer**. Однако при применении трансформеров для семантической сегментации есть несколько особенностей и ограничений, которые следует учитывать.

### Преимущества трансформеров для семантической сегментации

1. **Глобальный контекст**:
   - Трансформеры обладают способностью обрабатывать всю информацию изображения за один проход благодаря механизму **self-attention** (самовнимание), что позволяет учитывать глобальный контекст. Это может быть полезно для сегментации, где важно понять взаимосвязь между объектами на разных участках изображения.
   - В традиционных сверточных нейронных сетях (CNN) такие связи могут быть утеряны из-за локальности свёрток, особенно при обработке крупных объектов или сцен с множеством элементов.

2. **Обработка больших объектов и сложных сцен**:
   - Благодаря глобальному вниманию трансформеры могут лучше справляться с задачами, связанными с крупными объектами и сцены, где необходимо учитывать взаимодействие разных частей изображения, например, для правильной сегментации объектов, находящихся далеко друг от друга.

3. **Многомасштабные представления**:
   - Многие трансформерные архитектуры, такие как **Swin Transformer**, используют многоуровневые представления, которые эффективно обрабатывают информацию на разных масштабах. Это может быть особенно полезно для сегментации объектов разных размеров.

4. **Гибкость**:
   - Трансформеры могут быть адаптированы под задачи сегментации с помощью различных архитектур, таких как **SegFormer** или **Vision Transformer** (ViT), которые используют трансформеры как основу для обработки изображений и сегментации на уровне пикселей.

### Ограничения при использовании трансформеров для семантической сегментации

1. **Большие требования к вычислительным ресурсам**:
   - Одним из самых значительных ограничений трансформерных архитектур является их **высокая вычислительная сложность**. Механизм **self-attention** требует вычисления всех парных взаимодействий между пикселями изображения, что даёт **время работы порядка O(N²)**, где \( N \) — количество пикселей. Для изображений с высоким разрешением это может привести к значительному увеличению времени обучения и использованию памяти.
   - В случае очень больших изображений или видео сегментации, это может стать серьезной проблемой.

2. **Недостаточная локальность**:
   - В отличие от свёрточных сетей, трансформеры изначально не обладают хорошей способностью улавливать **локальные признаки** (например, края объектов, текстуры), что важно для задач семантической сегментации. Хотя self-attention может охватывать глобальный контекст, это не всегда заменяет локальные признаки, которые свёртки могут извлекать более эффективно.
   - Для улучшения локальности трансформеры часто комбинируются с CNN-слоями, но это добавляет сложности в архитектуру.

3. **Необходимость в большом количестве данных для обучения**:
   - Трансформеры требуют **больших объёмов данных** для эффективного обучения. Если данных недостаточно, модель может не научиться эффективно обрабатывать изображение и давать плохие результаты. В отличие от свёрточных нейронных сетей, которые могут обучаться на меньших датасетах, трансформеры склонны к переобучению на ограниченных данных.

4. **Проблемы с обработкой высокоразмерных данных**:
   - Для изображений с высокой разрешающей способностью трансформеры могут сталкиваться с проблемами из-за ограничений памяти и вычислительных мощностей. Особенно в случае моделей с самовниманием, которые требуют хранения и обработки больших матриц внимания для каждого пикселя.

5. **Оптимизация гиперпараметров**:
   - Модели на основе трансформеров могут требовать более сложной настройки гиперпараметров, таких как размер пакета, скорость обучения, количество слоев и другие. Это может увеличить время разработки и обучения модели.

### Примеры использования трансформеров для сегментации

1. **SegFormer**:
   - Это модель, которая использует трансформеры для задачи семантической сегментации. Она сочетает в себе преимущества глобального внимания и эффективной обработки различных масштабов данных, и при этом эффективно решает проблему вычислительных ресурсов с помощью оптимизированных архитектур.

2. **Swin Transformer**:
   - Это трансформер, который использует технику **shifted windows** для уменьшения вычислительной сложности. Swin Transformer можно адаптировать для задач сегментации, где важно учитывать как локальные, так и глобальные контексты.

3. **DeepLabV3+** с **Transformer**:
   - В последние годы были предложены гибридные архитектуры, которые комбинируют трансформеры с традиционными свёрточными нейронными сетями, например, **DeepLabV3+**, улучшенная за счёт использования механизмов внимания, для эффективной семантической сегментации.

### Заключение

Трансформерные архитектуры могут быть очень полезными для семантической сегментации, особенно в контексте учёта глобальных зависимостей и улучшенной обработки сложных сцен. Однако, из-за высокой вычислительной сложности и требований к данным, они могут сталкиваться с проблемами при обучении на изображениях с высоким разрешением или ограниченными вычислительными ресурсами. Эти ограничения можно минимизировать с помощью оптимизаций и гибридных архитектур, которые комбинируют лучшие черты как трансформеров, так и сверточных сетей.

## 5. Какая метрика используется для оценки качества таких моделей и как она вычисляется?

Для оценки качества моделей семантической сегментации обычно используются несколько метрик, которые отражают точность и эффективность предсказания пиксельных меток. Наиболее распространенные метрики включают:

### 1. **Доля пикселей, правильно классифицированных (Pixel Accuracy)**
   Это базовая метрика, которая измеряет процент пикселей, для которых модель предсказала правильный класс. Формула выглядит следующим образом:

   \[
   \text{Pixel Accuracy} = \frac{\text{Количество правильно классифицированных пикселей}}{\text{Общее количество пикселей}}
   \]

   Эта метрика проста в вычислении, но она не всегда даёт полное представление о качестве сегментации, особенно если классы сильно несбалансированы.

### 2. **Средняя точность по классам (Mean Pixel Accuracy)**
   Эта метрика учитывает точность сегментации для каждого класса отдельно и вычисляет среднее значение. Это особенно полезно, если классы в задаче сегментации сильно различаются по размеру.

   \[
   \text{Mean Pixel Accuracy} = \frac{1}{C} \sum_{i=1}^{C} \frac{TP_i}{TP_i + FN_i}
   \]
   где:
   - \(C\) — количество классов,
   - \(TP_i\) — количество истинно положительных пикселей для класса \(i\),
   - \(FN_i\) — количество ложно отрицательных пикселей для класса \(i\).

   Это даёт более точную картину того, насколько хорошо модель справляется с каждым отдельным классом.

### 3. **Intersection over Union (IoU)** или **Объединение на пересечение**
   **IoU** является одной из самых популярных метрик для задач сегментации, так как она отражает как хорошо предсказанная область пересекается с истинной областью (ground truth) с учётом их объединения. Это более строгая метрика, чем Pixel Accuracy, потому что она штрафует за ошибочные предсказания, особенно для сложных объектов или классов.

   Для одного класса IoU рассчитывается как:

   \[
   \text{IoU} = \frac{\text{TP}}{\text{TP} + \text{FP} + \text{FN}}
   \]
   где:
   - \(TP\) — количество истинно положительных пикселей,
   - \(FP\) — количество ложно положительных пикселей,
   - \(FN\) — количество ложно отрицательных пикселей.

   Для всех классов можно вычислить среднее значение IoU:

   \[
   \text{Mean IoU} = \frac{1}{C} \sum_{i=1}^{C} \text{IoU}_i
   \]

   IoU даёт более точную оценку того, насколько хорошо модель разделяет объекты, так как она не только учитывает правильные предсказания, но и ошибочные.

### 4. **Dice Coefficient (или Dice Similarity Coefficient, DSC)**
   Dice Coefficient — это метрика, аналогичная IoU, но она более чувствительна к ошибкам на небольших объектах, так как основывается на количестве общих пикселей между предсказанием и истинной меткой. Формула для DSC:

   \[
   \text{Dice} = \frac{2 \times TP}{2 \times TP + FP + FN}
   \]

   Dice также используется для оценки качества сегментации, и его значение находится в диапазоне от 0 до 1, где 1 означает полное совпадение с истинной меткой.

   **Mean Dice** вычисляется как среднее значение для всех классов:

   \[
   \text{Mean Dice} = \frac{1}{C} \sum_{i=1}^{C} \text{Dice}_i
   \]

   Dice схож с IoU, но за счет умножения на 2 более чувствителен к меньшим пересечениям, что полезно для сегментации мелких объектов.

### 5. **Frequency Weighted Intersection over Union (FWIoU)**
   Эта метрика модифицирует стандартный IoU, взвешивая его по частоте появления каждого класса в изображении. Это полезно для задач, где классы сильно несбалансированы.

   \[
   \text{FWIoU} = \sum_{i=1}^{C} \frac{\text{Area}_i}{\text{Total Area}} \times \text{IoU}_i
   \]
   где:
   - \(\text{Area}_i\) — площадь (количество пикселей) класса \(i\),
   - \(\text{Total Area}\) — общая площадь (все пиксели).

   FWIoU учитывает не только точность предсказаний, но и насколько часто каждый класс встречается в данных, что помогает избежать перекоса в сторону классов с меньшей частотой.

### 6. **Mean Average Precision (mAP)**
   **mAP** часто используется в задачах, где сегментация должна учитывать несколько объектов одного класса (например, в детекции объектов). В контексте семантической сегментации можно вычислить **average precision** для каждого класса, а затем усреднить их.

### 7. **Boundary F1 Score**
   Это метрика, которая фокусируется на оценке точности границ сегментированных объектов. Она полезна для оценки, насколько хорошо модель воспроизводит контуры объектов. Формула для вычисления Boundary F1 Score учитывает пересечение границ и правильно предсказанные границы:

   \[
   \text{Boundary F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
   \]
   где:
   - **Precision** — доля предсказанных пикселей, которые действительно принадлежат границе,
   - **Recall** — доля истинных пикселей, которые были правильно предсказаны как часть границы.

### Заключение
Для оценки моделей семантической сегментации в основном используются метрики, такие как **IoU**, **Dice Coefficient**, **Pixel Accuracy**, и **Mean IoU**, так как они хорошо отражают качество предсказаний на уровне пикселей и обеспечивают точную оценку, как модель справляется с разными классами и объектами. Для задач с несбалансированными классами часто применяют **Frequency Weighted IoU** или **mAP**.
